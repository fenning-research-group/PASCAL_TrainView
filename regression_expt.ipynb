{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Experiment\n",
    "Try regression on input parameters (sampledataframe, maestronetlist) to determine characterization metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frgpascal.analysis.processing import load_all\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json # load maestro logs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import index_natsorted\n",
    "\n",
    "def load_all_sorted(chardir):\n",
    "\tmetricdf, rawdf = load_all(\n",
    "\t\tchardir,\n",
    "\t\tt_kwargs=dict(\n",
    "\t\t\twlmin=700,\n",
    "\t\t\twlmax=900\n",
    "\t\t)\n",
    "\t)\n",
    "\trawdf= rawdf.sort_values(\n",
    "   \t\tby='name',\n",
    "   \t\tkey=lambda x: np.argsort(index_natsorted(rawdf['name']))\n",
    "    )\n",
    "\trawdf = rawdf.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\tmetricdf= metricdf.sort_values(\n",
    "    \tby='name',\n",
    "    \tkey=lambda x: np.argsort(index_natsorted(metricdf['name']))\n",
    "    )\n",
    "\tmetricdf = metricdf.reset_index(drop=True)\n",
    "\treturn metricdf, rawdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: clean up this code, perhaps put into separate utilities script\n",
    "\n",
    "\n",
    "def line_defect_p(img):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - img: a 3-channel RGB image\n",
    "\n",
    "    Returns:\n",
    "    - a float, representing the proportion of the image area taken up by lines\n",
    "    - a numpy array, representing the image run through line detection algorithm\n",
    "    - a list of tuples, representing the lines found\n",
    "    '''\n",
    "\n",
    "    # NOTE: this currently does not discriminate between lines and splotches (which are shaped as round-ish fractals)\n",
    "    # will need to fix up to only select lines\n",
    "\n",
    "    # if image channels were in float format [0,1], then\n",
    "    # convert image channels to uint8 format [0,255]\n",
    "    # manual scaling seems better than cv2.normalize function, which might map a float <1 to 255\n",
    "    # which seems to produce line artificts\n",
    "    if np.issubdtype(img.dtype, np.floating):\n",
    "        img = np.uint8(255*img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # convert brightfield image to grayscale\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(gray, 40, 60, apertureSize=3)\n",
    "    edges_dilated = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=1) # dilate to expand the edges and connect lines\n",
    "\n",
    "    # apply hough lines transform to find lines\n",
    "    # may need to tune resolution and threshold parameters\n",
    "    minLineLength = edges_dilated.shape[0]*0.03 # 3% of the width of the image\n",
    "    maxLineGap = 30 # higher means more lines combined together so there are less overall\n",
    "    lines = cv2.HoughLinesP(edges_dilated, 1, np.pi/180, 100, minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "    if lines is None:\n",
    "        lines = np.zeros(0)\n",
    "\n",
    "    # now visualize the lines\n",
    "    line_img = np.zeros(gray.shape)\n",
    "    for l in lines:\n",
    "        arr = np.array(l[0], dtype=np.int32)\n",
    "        x1, y1, x2, y2 = arr\n",
    "\n",
    "        # cv.line draws a line in img from the point(x1,y1) to (x2,y2).\n",
    "        # 255 denotes the colour of the line to be drawn\n",
    "        cv2.line(line_img, (x1, y1), (x2, y2), color=255, thickness=2)\n",
    "\n",
    "    return line_img.sum()/line_img.size/255, line_img, lines\n",
    "\n",
    "\n",
    "def defect_p(img):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - img: a 3-channel RGB image\n",
    "\n",
    "    Returns:\n",
    "    - a tuple of floats, representing the proportion of the image area taken up by each defect (line, splotches)\n",
    "    - a tuple of numpy arrays, representing the image run through defect detection algorithm (line, splotches)\n",
    "    '''\n",
    "\n",
    "    # if image channels were in float format [0,1], then\n",
    "    # convert image channels to uint8 format [0,255]\n",
    "    # manual scaling seems better than cv2.normalize function, which might map a float <1 to 255\n",
    "    # which seems to produce line artificts\n",
    "    if np.issubdtype(img.dtype, np.floating):\n",
    "        img = np.uint8(255*img)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # convert brightfield image to grayscale\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(gray, 40, 60, apertureSize=3)\n",
    "    edges_dilated = cv2.dilate(edges, np.ones((5,5), np.uint8), iterations=1) # dilate to expand the edges and connect lines\n",
    "    # now find the contours\n",
    "    contours, _ = cv2.findContours(edges_dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cont_img = np.zeros(edges_dilated.shape, np.uint8)\n",
    "    cont_img = cv2.drawContours(cont_img, contours, -1, color=255, thickness=3)\n",
    "\n",
    "    # now perform a floodfill to separate contour exterior from interior\n",
    "    # anything \"outside\" a defect is connected, and anything \"inside\" a defect is connected\n",
    "    \n",
    "    # first add padding to outside so that any lines that bisect the image don't mess up the floodfill\n",
    "    b = 1 # border padding amount\n",
    "    cont_img = cv2.copyMakeBorder(cont_img, b, b, b, b, cv2.BORDER_CONSTANT, 0)\n",
    "    h, w = cont_img.shape\n",
    "    mask = np.zeros((h+2, w+2), np.uint8) # floodfill mask\n",
    "    cv2.floodFill(cont_img, mask, (0,0), 123) # fill with grey so it doesn't obscure edges\n",
    "    cont_img = cv2.inRange(cont_img, 122, 124) # threshold so that anything outside a defect\n",
    "    cont_img = cv2.bitwise_not(cont_img) # now invert colors so that contour interior is white and exterior is black\n",
    "    cont_img = cont_img[b:-b, b:-b] # now crop to remove border padding\n",
    "\n",
    "    # now remove lines from the contour image so we're just left with splotches and circles\n",
    "    remove_lines_img = line_defect_p(cv2.cvtColor(cont_img, cv2.COLOR_GRAY2RGB))[1]\n",
    "    line_img_dilate = cv2.dilate(remove_lines_img, np.ones((5,5)), iterations=1) # dilate lines so that we're sure we remove them\n",
    "    cont_img = np.maximum(0, cont_img - line_img_dilate) # subtract out lines and rectify\n",
    "    cont_img = cv2.erode(cont_img, np.ones((5,5)), iterations=1) # erode contours to remove any leftover lines\n",
    "    cont_img = cv2.dilate(cont_img, np.ones((5,5)), iterations=1) # now get back the area in the real contours that was eroded\n",
    "\n",
    "    # now remove splotches from the line image so it only has lines\n",
    "    line_img = line_defect_p(img)[1]\n",
    "    cont_img_dilate = cv2.dilate(cont_img, np.ones((5,5)), iterations = 1)\n",
    "    line_img = np.maximum(0, line_img - cont_img_dilate) # subtract out splotches and rectify\n",
    "\n",
    "    # compute proportion of image taken up by defects\n",
    "    cont_p = cont_img.sum()/cont_img.size/255\n",
    "    line_p = line_img.sum()/line_img.size/255\n",
    "\n",
    "    return (line_p, cont_p), (line_img, cont_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Characterization Metrics\n",
    "This includes fitted characterization metrics + other metrics we define on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/output/20221011_B9-char_1/Characterization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:   0%|          | 0/31 [00:00<?, ?sample/s]/home/kcw/anaconda3/envs/fenning/lib/python3.7/site-packages/frgpascal/analysis/processing.py:103: RuntimeWarning: invalid value encountered in log10\n",
      "  a = -np.log10(t)\n",
      "Loading data:  13%|█▎        | 4/31 [00:02<00:14,  1.82sample/s]/home/kcw/anaconda3/envs/fenning/lib/python3.7/site-packages/frgpascal/analysis/processing.py:103: RuntimeWarning: divide by zero encountered in log10\n",
      "  a = -np.log10(t)\n",
      "Loading data: 100%|██████████| 31/31 [00:16<00:00,  1.87sample/s]\n"
     ]
    }
   ],
   "source": [
    "# first load output data (characterization metrics)\n",
    "# TODO: use a tf.data.Dataset to stream data in so we can load more without memory constraints\n",
    "\n",
    "chardir_0 = ['data/output/20221011_B9-char_1/Characterization']\n",
    "\n",
    "metricdf = None\n",
    "for dir in chardir_0:\n",
    "    print(f'Loading {dir}')\n",
    "    # load data from directory\n",
    "    mdf, rdf = load_all_sorted(dir)\n",
    "    # record what batch it came from\n",
    "    mdf['batch'] = dir\n",
    "    rdf['batch'] = dir\n",
    "\n",
    "    # instead of saving the images, extract metrics from them\n",
    "    # df_metrics = pd.DataFrame(rdf['df_0'].apply(lambda img: defect_p(img)[0]))\n",
    "    # print(df_metrics.head(4))\n",
    "    bf_metrics = rdf['bf_0'].apply(lambda img: defect_p(img)[0])\n",
    "    bf_metrics = pd.DataFrame(bf_metrics.to_list(), columns=['bf_linep_0', 'bf_splotchp_0'])\n",
    "    # pl_metrics = pd.DataFrame(rdf['plimg_0'].apply(lambda img: defect_p(img)[0]))\n",
    "\n",
    "    mdf = mdf.join(bf_metrics)\n",
    "    # now add it to collective dataframe\n",
    "    metricdf = pd.concat([metricdf, mdf])\n",
    "\n",
    "\n",
    "    del mdf, rdf # explicitly delete to save memory cause HD images use a LOT\n",
    "\n",
    "# reset indices so the sample number doesn't interfere with indexing\n",
    "metricdf = metricdf.reset_index().rename(columns={'index': 'sample_num'})\n",
    "metricdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>sample_num</th>\n",
       "      <th>name</th>\n",
       "      <th>bf_inhomogeneity_0</th>\n",
       "      <th>bf_linep_0</th>\n",
       "      <th>bf_splotchp_0</th>\n",
       "      <th>df_median_0</th>\n",
       "      <th>pl_fwhm_0</th>\n",
       "      <th>pl_intensity_0</th>\n",
       "      <th>pl_peakev_0</th>\n",
       "      <th>t_bandgap_0</th>\n",
       "      <th>t_samplepresent_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>0</td>\n",
       "      <td>sample0</td>\n",
       "      <td>0.154434</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>140.035843</td>\n",
       "      <td>0.096823</td>\n",
       "      <td>174.176938</td>\n",
       "      <td>1.677392</td>\n",
       "      <td>1.670885</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>1</td>\n",
       "      <td>sample1</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>140.845169</td>\n",
       "      <td>0.098287</td>\n",
       "      <td>175.216607</td>\n",
       "      <td>1.676216</td>\n",
       "      <td>1.669811</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>2</td>\n",
       "      <td>sample2</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>140.304779</td>\n",
       "      <td>0.097397</td>\n",
       "      <td>253.082279</td>\n",
       "      <td>1.677381</td>\n",
       "      <td>1.669848</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>3</td>\n",
       "      <td>sample3</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>139.916306</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>183.368298</td>\n",
       "      <td>1.677104</td>\n",
       "      <td>1.664593</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>4</td>\n",
       "      <td>sample4</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>140.987106</td>\n",
       "      <td>0.096425</td>\n",
       "      <td>279.598707</td>\n",
       "      <td>1.677065</td>\n",
       "      <td>1.669493</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>5</td>\n",
       "      <td>sample5</td>\n",
       "      <td>0.12381</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.019091</td>\n",
       "      <td>140.95224</td>\n",
       "      <td>0.095493</td>\n",
       "      <td>210.086825</td>\n",
       "      <td>1.67696</td>\n",
       "      <td>1.669777</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>6</td>\n",
       "      <td>sample6</td>\n",
       "      <td>0.032335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>141.803909</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>235.359654</td>\n",
       "      <td>1.677107</td>\n",
       "      <td>1.669393</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>7</td>\n",
       "      <td>sample7</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>141.101654</td>\n",
       "      <td>0.096087</td>\n",
       "      <td>160.327952</td>\n",
       "      <td>1.676423</td>\n",
       "      <td>1.669312</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>8</td>\n",
       "      <td>sample8</td>\n",
       "      <td>0.052047</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>140.71817</td>\n",
       "      <td>0.098563</td>\n",
       "      <td>176.236739</td>\n",
       "      <td>1.676698</td>\n",
       "      <td>1.671236</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>9</td>\n",
       "      <td>sample9</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>140.060745</td>\n",
       "      <td>0.101346</td>\n",
       "      <td>83.560557</td>\n",
       "      <td>1.677186</td>\n",
       "      <td>1.669862</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>10</td>\n",
       "      <td>sample10</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>141.744141</td>\n",
       "      <td>0.111875</td>\n",
       "      <td>107.442715</td>\n",
       "      <td>1.672887</td>\n",
       "      <td>1.666112</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>11</td>\n",
       "      <td>sample11</td>\n",
       "      <td>0.033831</td>\n",
       "      <td>0.007440</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>140.344635</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>211.420181</td>\n",
       "      <td>1.676783</td>\n",
       "      <td>1.670905</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>12</td>\n",
       "      <td>sample12</td>\n",
       "      <td>0.040635</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>139.806732</td>\n",
       "      <td>0.100575</td>\n",
       "      <td>170.721722</td>\n",
       "      <td>1.678077</td>\n",
       "      <td>1.666388</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>13</td>\n",
       "      <td>sample13</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>140.733109</td>\n",
       "      <td>0.110211</td>\n",
       "      <td>52.100854</td>\n",
       "      <td>1.674937</td>\n",
       "      <td>1.667409</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>14</td>\n",
       "      <td>sample14</td>\n",
       "      <td>0.036611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>140.822754</td>\n",
       "      <td>0.10033</td>\n",
       "      <td>152.215861</td>\n",
       "      <td>1.676681</td>\n",
       "      <td>1.670764</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>15</td>\n",
       "      <td>sample15</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>141.161423</td>\n",
       "      <td>0.104624</td>\n",
       "      <td>151.625384</td>\n",
       "      <td>1.676931</td>\n",
       "      <td>1.669535</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>16</td>\n",
       "      <td>sample16</td>\n",
       "      <td>0.03359</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>140.932327</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>177.228973</td>\n",
       "      <td>1.676157</td>\n",
       "      <td>1.669735</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>17</td>\n",
       "      <td>sample17</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>141.793945</td>\n",
       "      <td>0.105012</td>\n",
       "      <td>107.646644</td>\n",
       "      <td>1.674785</td>\n",
       "      <td>1.66581</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>18</td>\n",
       "      <td>sample18</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>141.79892</td>\n",
       "      <td>0.105943</td>\n",
       "      <td>184.920921</td>\n",
       "      <td>1.67513</td>\n",
       "      <td>1.672076</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>19</td>\n",
       "      <td>sample19</td>\n",
       "      <td>0.034223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>141.405472</td>\n",
       "      <td>0.110402</td>\n",
       "      <td>123.11248</td>\n",
       "      <td>1.675304</td>\n",
       "      <td>1.671145</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>20</td>\n",
       "      <td>sample20</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>139.956146</td>\n",
       "      <td>0.112455</td>\n",
       "      <td>95.816118</td>\n",
       "      <td>1.67385</td>\n",
       "      <td>1.670203</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>21</td>\n",
       "      <td>sample21</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>142.431442</td>\n",
       "      <td>0.102888</td>\n",
       "      <td>89.627224</td>\n",
       "      <td>1.671707</td>\n",
       "      <td>1.663931</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>22</td>\n",
       "      <td>sample22</td>\n",
       "      <td>0.033678</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>140.867584</td>\n",
       "      <td>0.102443</td>\n",
       "      <td>143.394995</td>\n",
       "      <td>1.674272</td>\n",
       "      <td>1.667954</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>23</td>\n",
       "      <td>sample23</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>141.126556</td>\n",
       "      <td>0.106769</td>\n",
       "      <td>92.03633</td>\n",
       "      <td>1.675329</td>\n",
       "      <td>1.663696</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>24</td>\n",
       "      <td>sample24</td>\n",
       "      <td>0.035962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>141.764069</td>\n",
       "      <td>0.101292</td>\n",
       "      <td>167.075145</td>\n",
       "      <td>1.674497</td>\n",
       "      <td>1.667693</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>25</td>\n",
       "      <td>sample25</td>\n",
       "      <td>0.047862</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>140.897461</td>\n",
       "      <td>0.104035</td>\n",
       "      <td>123.994673</td>\n",
       "      <td>1.67445</td>\n",
       "      <td>1.666135</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>26</td>\n",
       "      <td>sample26</td>\n",
       "      <td>0.045216</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>141.52002</td>\n",
       "      <td>0.104085</td>\n",
       "      <td>140.295618</td>\n",
       "      <td>1.674809</td>\n",
       "      <td>1.669075</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>27</td>\n",
       "      <td>sample27</td>\n",
       "      <td>0.032996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>141.241119</td>\n",
       "      <td>0.107498</td>\n",
       "      <td>130.426999</td>\n",
       "      <td>1.673812</td>\n",
       "      <td>1.668323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>28</td>\n",
       "      <td>sample28</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>141.903519</td>\n",
       "      <td>0.102368</td>\n",
       "      <td>156.538718</td>\n",
       "      <td>1.674862</td>\n",
       "      <td>1.666768</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>29</td>\n",
       "      <td>sample29</td>\n",
       "      <td>0.037097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>141.211227</td>\n",
       "      <td>0.115027</td>\n",
       "      <td>72.19809</td>\n",
       "      <td>1.66909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>data/output/20221011_B9-char_1/Characterization</td>\n",
       "      <td>30</td>\n",
       "      <td>sample30</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>140.972168</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>136.054667</td>\n",
       "      <td>1.675745</td>\n",
       "      <td>1.668319</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              batch  sample_num      name  \\\n",
       "0   data/output/20221011_B9-char_1/Characterization           0   sample0   \n",
       "1   data/output/20221011_B9-char_1/Characterization           1   sample1   \n",
       "2   data/output/20221011_B9-char_1/Characterization           2   sample2   \n",
       "3   data/output/20221011_B9-char_1/Characterization           3   sample3   \n",
       "4   data/output/20221011_B9-char_1/Characterization           4   sample4   \n",
       "5   data/output/20221011_B9-char_1/Characterization           5   sample5   \n",
       "6   data/output/20221011_B9-char_1/Characterization           6   sample6   \n",
       "7   data/output/20221011_B9-char_1/Characterization           7   sample7   \n",
       "8   data/output/20221011_B9-char_1/Characterization           8   sample8   \n",
       "9   data/output/20221011_B9-char_1/Characterization           9   sample9   \n",
       "10  data/output/20221011_B9-char_1/Characterization          10  sample10   \n",
       "11  data/output/20221011_B9-char_1/Characterization          11  sample11   \n",
       "12  data/output/20221011_B9-char_1/Characterization          12  sample12   \n",
       "13  data/output/20221011_B9-char_1/Characterization          13  sample13   \n",
       "14  data/output/20221011_B9-char_1/Characterization          14  sample14   \n",
       "15  data/output/20221011_B9-char_1/Characterization          15  sample15   \n",
       "16  data/output/20221011_B9-char_1/Characterization          16  sample16   \n",
       "17  data/output/20221011_B9-char_1/Characterization          17  sample17   \n",
       "18  data/output/20221011_B9-char_1/Characterization          18  sample18   \n",
       "19  data/output/20221011_B9-char_1/Characterization          19  sample19   \n",
       "20  data/output/20221011_B9-char_1/Characterization          20  sample20   \n",
       "21  data/output/20221011_B9-char_1/Characterization          21  sample21   \n",
       "22  data/output/20221011_B9-char_1/Characterization          22  sample22   \n",
       "23  data/output/20221011_B9-char_1/Characterization          23  sample23   \n",
       "24  data/output/20221011_B9-char_1/Characterization          24  sample24   \n",
       "25  data/output/20221011_B9-char_1/Characterization          25  sample25   \n",
       "26  data/output/20221011_B9-char_1/Characterization          26  sample26   \n",
       "27  data/output/20221011_B9-char_1/Characterization          27  sample27   \n",
       "28  data/output/20221011_B9-char_1/Characterization          28  sample28   \n",
       "29  data/output/20221011_B9-char_1/Characterization          29  sample29   \n",
       "30  data/output/20221011_B9-char_1/Characterization          30  sample30   \n",
       "\n",
       "   bf_inhomogeneity_0  bf_linep_0  bf_splotchp_0 df_median_0 pl_fwhm_0  \\\n",
       "0            0.154434    0.001388       0.034574  140.035843  0.096823   \n",
       "1            0.034818    0.000000       0.003450  140.845169  0.098287   \n",
       "2            0.033021    0.000000       0.002436  140.304779  0.097397   \n",
       "3            0.036609    0.000000       0.002884  139.916306  0.097168   \n",
       "4            0.031844    0.000000       0.002175  140.987106  0.096425   \n",
       "5             0.12381    0.013432       0.019091   140.95224  0.095493   \n",
       "6            0.032335    0.000000       0.002328  141.803909  0.096805   \n",
       "7            0.034108    0.000000       0.002494  141.101654  0.096087   \n",
       "8            0.052047    0.004770       0.008308   140.71817  0.098563   \n",
       "9            0.036251    0.000000       0.002654  140.060745  0.101346   \n",
       "10           0.032895    0.003753       0.004025  141.744141  0.111875   \n",
       "11           0.033831    0.007440       0.003980  140.344635  0.098336   \n",
       "12           0.040635    0.010782       0.003558  139.806732  0.100575   \n",
       "13           0.033823    0.001642       0.004208  140.733109  0.110211   \n",
       "14           0.036611    0.000000       0.001880  140.822754   0.10033   \n",
       "15           0.033195    0.000000       0.003176  141.161423  0.104624   \n",
       "16            0.03359    0.001087       0.006377  140.932327   0.09968   \n",
       "17           0.032907    0.000000       0.003747  141.793945  0.105012   \n",
       "18           0.032233    0.000000       0.001900   141.79892  0.105943   \n",
       "19           0.034223    0.000000       0.002999  141.405472  0.110402   \n",
       "20           0.036617    0.000000       0.003304  139.956146  0.112455   \n",
       "21           0.031851    0.000000       0.002382  142.431442  0.102888   \n",
       "22           0.033678    0.002362       0.003184  140.867584  0.102443   \n",
       "23           0.035633    0.000124       0.005261  141.126556  0.106769   \n",
       "24           0.035962    0.000000       0.002910  141.764069  0.101292   \n",
       "25           0.047862    0.011568       0.003556  140.897461  0.104035   \n",
       "26           0.045216    0.010411       0.004412   141.52002  0.104085   \n",
       "27           0.032996    0.000000       0.001874  141.241119  0.107498   \n",
       "28            0.03244    0.000000       0.002469  141.903519  0.102368   \n",
       "29           0.037097    0.000000       0.003726  141.211227  0.115027   \n",
       "30           0.034976    0.000000       0.003022  140.972168  0.103236   \n",
       "\n",
       "   pl_intensity_0 pl_peakev_0 t_bandgap_0 t_samplepresent_0  \n",
       "0      174.176938    1.677392    1.670885              True  \n",
       "1      175.216607    1.676216    1.669811              True  \n",
       "2      253.082279    1.677381    1.669848              True  \n",
       "3      183.368298    1.677104    1.664593              True  \n",
       "4      279.598707    1.677065    1.669493              True  \n",
       "5      210.086825     1.67696    1.669777              True  \n",
       "6      235.359654    1.677107    1.669393              True  \n",
       "7      160.327952    1.676423    1.669312              True  \n",
       "8      176.236739    1.676698    1.671236              True  \n",
       "9       83.560557    1.677186    1.669862              True  \n",
       "10     107.442715    1.672887    1.666112              True  \n",
       "11     211.420181    1.676783    1.670905              True  \n",
       "12     170.721722    1.678077    1.666388              True  \n",
       "13      52.100854    1.674937    1.667409              True  \n",
       "14     152.215861    1.676681    1.670764              True  \n",
       "15     151.625384    1.676931    1.669535              True  \n",
       "16     177.228973    1.676157    1.669735              True  \n",
       "17     107.646644    1.674785     1.66581              True  \n",
       "18     184.920921     1.67513    1.672076              True  \n",
       "19      123.11248    1.675304    1.671145              True  \n",
       "20      95.816118     1.67385    1.670203              True  \n",
       "21      89.627224    1.671707    1.663931              True  \n",
       "22     143.394995    1.674272    1.667954              True  \n",
       "23       92.03633    1.675329    1.663696              True  \n",
       "24     167.075145    1.674497    1.667693              True  \n",
       "25     123.994673     1.67445    1.666135              True  \n",
       "26     140.295618    1.674809    1.669075              True  \n",
       "27     130.426999    1.673812    1.668323              True  \n",
       "28     156.538718    1.674862    1.666768              True  \n",
       "29       72.19809     1.66909         NaN              True  \n",
       "30     136.054667    1.675745    1.668319              True  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort metric columns alphabetically\n",
    "metricdf = metricdf.sort_index(axis=1)\n",
    "a = metricdf[['batch', 'sample_num', 'name']] # put these columns in front\n",
    "b = metricdf.drop(columns=['batch', 'name', 'sample_num']) # the actual metrics \n",
    "metricdf = a.join(b)\n",
    "metricdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('fenning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad621d8068219fb334f0f19d776ddde8a155fd93f03e3bff35ed591b43d39916"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
