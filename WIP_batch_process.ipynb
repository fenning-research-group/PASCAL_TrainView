{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frgpascal.analysis.processing import load_all, compress_jv, get_worklist_times\n",
    "from scipy import stats\n",
    "from natsort import natsorted\n",
    "from natsort import index_natsorted\n",
    "import copy\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.colorbar\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import os\n",
    "import json\n",
    "import pickle as pkl\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['axes.linewidth'] = 1.75 #set the value globally\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_params(paramdf):\n",
    "    data = {}\n",
    "    # data['storage_tray'] = []\n",
    "    data['sample_number'] = []\n",
    "    data['substrate'] = []\n",
    "\n",
    "\n",
    "    # data['spincoat1_drop1_time'] = []\n",
    "    # data['spincoat1_drop1_rate'] = []\n",
    "    # data['spincoat1_drop1_height'] = []\n",
    "    # data['spincoat1_drop1_volume'] = []\n",
    "\n",
    "\n",
    "    for n in range(len(paramdf)):\n",
    "        sample_number = paramdf['name'][n]\n",
    "        substrate = paramdf['substrate'][n]\n",
    "        # storage_tray = paramdf['storage_tray'][n]\n",
    "        \n",
    "        # spincoat1_drop1_time = paramdf['spincoat1_drop1_time'][n]\n",
    "        # spincoat1_drop1_rate = paramdf['spincoat1_drop1_rate'][n]\n",
    "        # spincoat1_drop1_height = paramdf['spincoat1_drop1_height'][n]\n",
    "        # spincoat1_drop1_volume = paramdf['spincoat1_drop1_volume'][n]\n",
    "\n",
    "\n",
    "        data['sample_number'].append(sample_number)\n",
    "        data['substrate'].append(substrate)\n",
    "\n",
    "        # data['spincoat1_drop1_time'].append(spincoat1_drop1_time)\n",
    "        # data['spincoat1_drop1_rate'].append(spincoat1_drop1_rate)\n",
    "        # data['spincoat1_drop1_height'].append(spincoat1_drop1_height)\n",
    "        # data['spincoat1_drop1_volume'].append(spincoat1_drop1_volume)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_sorted(chardir):\n",
    "    metricdf, rawdf = load_all(\n",
    "        chardir,\n",
    "        t_kwargs=dict(\n",
    "            wlmin=700,\n",
    "            wlmax=900\n",
    "        )\n",
    "    )\n",
    "    rawdf= rawdf.sort_values(\n",
    "   by='name',\n",
    "   key=lambda x: np.argsort(index_natsorted(rawdf['name']))\n",
    "    )\n",
    "    rawdf = rawdf.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    metricdf= metricdf.sort_values(\n",
    "    by='name',\n",
    "    key=lambda x: np.argsort(index_natsorted(metricdf['name']))\n",
    "    )\n",
    "    metricdf = metricdf.reset_index(drop=True)\n",
    "    return metricdf, rawdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_time(timedf):\n",
    "    timedf_0 = timedf\n",
    "\n",
    "    time_list = []\n",
    "\n",
    "    for n in range(len(timedf_0)):\n",
    "        time_list.append(timedf_0['spincoat0'][n][0])\n",
    "        \n",
    "        \n",
    "    for n in range(len(timedf_0)):\n",
    "        timedf_0['spincoat0'][n] = time_list[n]\n",
    "    \n",
    "    return timedf_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_duplicate_cols(df):\n",
    "    df = df\n",
    "    cols=pd.Series(df.columns)\n",
    "\n",
    "    for dup in cols[cols.duplicated()].unique(): \n",
    "        cols[cols[cols == dup].index.values.tolist()] = [dup + '.' + str(i) if i != 0 else dup for i in range(sum(cols == dup))]\n",
    "\n",
    "    # rename the columns with the cols list.\n",
    "    df.columns=cols \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_plot(metricdf, x_col=str, y_col=str):\n",
    "    metricdf=metricdf\n",
    "    fig, ax = plt.subplots()\n",
    "    x = metricdf[x_col].astype(float)\n",
    "    y = metricdf[y_col].astype(float)\n",
    "    sns.scatterplot(x = x, y = y ,ax=ax, color='black', alpha=1, legend=None)\n",
    "    sns.kdeplot(x = x, y = y,  cmap=\"Greys_r\", shade=True, bw_method='scott', ax=ax, alpha=.2)\n",
    "    res = stats.linregress(x, y)\n",
    "    rsq = res.rvalue**2\n",
    "    ax.plot(x, res.intercept + res.slope*x, 'r')#, label=f'R$^2$:{rsq:.2f}', color='springgreen')\n",
    "    plt.text(0.01, .95, s = (f'R$^2$:{rsq:.2f}'), horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, color='red', weight='bold')\n",
    "    plt.ylabel(y.name, size=15)\n",
    "    plt.xlabel(x.name, size=15)\n",
    "    \n",
    "    TodaysDate = time.strftime(\"%Y%m%d\")\n",
    "    plt.savefig(f'{TodaysDate}_{x_col}_{y_col}.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(metricdf, method='pearson'):\n",
    "    metricdf = metricdf\n",
    "    columns = [\n",
    "    'pce_f',\n",
    "    'pce_r',\n",
    "    'ff_f',\n",
    "    'ff_r',\n",
    "    'voc_f',\n",
    "    'voc_r',\n",
    "    'jsc_f',\n",
    "    'jsc_r',\n",
    "    'pl_intensity_0',\n",
    "    'pl_peakev_0',\n",
    "    'pl_fwhm_0',\n",
    "    't_bandgap_0',\n",
    "    'spincoat0'\n",
    "    ]\n",
    "    d = metricdf[columns]\n",
    "    d = d.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Compute the correlation matrix\n",
    "    corr = d.corr(\n",
    "        method='pearson'\n",
    "        # method='kendall'\n",
    "\n",
    "    )\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    # mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    mask = np.eye(corr.shape[0])\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        mask=mask,\n",
    "        cmap=cmap,\n",
    "        # vmax=.7,\n",
    "        # vmin=-0.7,\n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=.5,\n",
    "        cbar_kws={\n",
    "            \"shrink\": .5,\n",
    "            \"label\": 'Pearson Correlation'\n",
    "        }\n",
    "    )\n",
    "    TodaysDate = time.strftime(\"%Y%m%d\")\n",
    "    plt.savefig(f'{TodaysDate}_correlation_matrix.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor(x):\n",
    "    factor_list = []\n",
    "    for i in range(1, x + 1):\n",
    "        if x % i == 0:\n",
    "            factor_list.append(i)\n",
    "    return factor_list\n",
    "\n",
    "def shape_plot(rawdf, x_aspect = 8):\n",
    "    count = len(rawdf)\n",
    "    \n",
    "    while (count % x_aspect) != 0:\n",
    "        count += 1\n",
    "\n",
    "    first_list = []\n",
    "    second_list = []\n",
    "    add_list = []\n",
    "    factor_list = factor(count)\n",
    "    for n in range(len(factor_list)):\n",
    "        first = factor_list[n]\n",
    "        first_list.append(first)\n",
    "        for m in range(len(factor_list)):\n",
    "            second = factor_list[m]\n",
    "            if first*second == count:\n",
    "                second_list.append(second)\n",
    "                add_list.append(first+second)\n",
    "                \n",
    "    first_list = np.array(first_list)\n",
    "    second_list = np.array(second_list)\n",
    "    add_list = np.array(add_list)   \n",
    "    return second_list[np.argmin(add_list)], first_list[np.argmin(add_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.linspace(0,32,61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_plot(test, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bf(rawdf):\n",
    "\n",
    "    blank = rawdf['bf_0'][0]*0\n",
    "    horiz, vert = shape_plot(rawdf, 8)\n",
    "\n",
    "    embiggen = 2\n",
    "    item = 0\n",
    "\n",
    "    fig, ax = plt.subplots(vert, horiz, figsize = (horiz*embiggen, vert*embiggen), constrained_layout=False)\n",
    "\n",
    "    for k in range(horiz):\n",
    "        for n in range(vert):\n",
    "            try:\n",
    "                name = rawdf['name'][item]\n",
    "                pl_intensity_0 = rawdf['pl_intensity_0'][item]\n",
    "                pl_peakev_0 = rawdf['pl_peakev_0'][item]\n",
    "                ax[n,k].imshow(rawdf['bf_0'][item])\n",
    "            except:\n",
    "                ax[n,k].imshow(blank)\n",
    "                name = 'eblank'\n",
    "                pl_intensity_0 = 0\n",
    "                pl_peakev_0 = 0\n",
    "                \n",
    "            try:\n",
    "                pce_r = rawdf['pce_f'][item]\n",
    "                ff_r = rawdf['ff_f'][item]\n",
    "            except:\n",
    "\n",
    "                pce_r = 0\n",
    "                ff_r = 0\n",
    "\n",
    "            plt.text(0.01, 1, s = (name.split('e')[1]), horizontalalignment='left', verticalalignment='top', transform=ax[n,k].transAxes, color='Red', weight='bold', backgroundcolor='White')\n",
    "            plt.text(0.01, .35, s = (f'PCEf: {pce_r:.2f}%'), horizontalalignment='left', verticalalignment='top', transform=ax[n,k].transAxes, color='lime', weight='bold')\n",
    "            plt.text(0.01, .45, s = (f'FFf: {ff_r:.2f}%'), horizontalalignment='left', verticalalignment='top', transform=ax[n,k].transAxes, color='lime', weight='bold')\n",
    "\n",
    "                \n",
    "            plt.text(0.01, 0.15, s = (f'PL-Cts: {pl_intensity_0:.1f}'), horizontalalignment='left', verticalalignment='top', transform=ax[n,k].transAxes, color='Yellow', weight='bold')\n",
    "            plt.text(0.01, 0, s = (f'PL-eV: {pl_peakev_0:.2f}'), horizontalalignment='left', verticalalignment='top', transform=ax[n,k].transAxes, color='Black', weight='bold')\n",
    "\n",
    "\n",
    "            item +=1\n",
    "            ax[n,k].set_xticks([])\n",
    "            ax[n,k].set_yticks([])\n",
    "            ax[n,k].axis('off')\n",
    "    fig.subplots_adjust(wspace=0, hspace=-.3)\n",
    "    TodaysDate = time.strftime(\"%Y%m%d\")\n",
    "    plt.savefig(f'{TodaysDate}_bf.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(batch =str, chardir=str, paramdir=str, logdir=str, jvdir=None, drop_low_pl = 50, save=True):\n",
    "    chardir_0 = chardir\n",
    "    paramdir_0 = paramdir\n",
    "    logdir_0 = logdir\n",
    "    jvdir_0 = jvdir\n",
    "    \n",
    "    TodaysDate = time.strftime(\"%Y%m%d\")\n",
    "    fp = \"{}_{}_analysis\".format(TodaysDate,batch)\n",
    "    if not os.path.exists(fp):\n",
    "        os.mkdir(fp)\n",
    "    os.chdir(fp)\n",
    "\n",
    "    paramdf_0 = pd.read_csv(paramdir_0)\n",
    "    paramdf_0 = paramdf_0.sort_values(by='name', key=lambda x: np.argsort(index_natsorted(paramdf_0['name'])))\n",
    "    paramdf_0 = paramdf_0.reset_index(drop=True)\n",
    "    metricdf_0, rawdf_0 = load_all_sorted(chardir_0)\n",
    "    timedf_0 = adjust_time(get_worklist_times(logdir_0))\n",
    "\n",
    "    if jvdir_0 !=None:\n",
    "        jvdf_0 = compress_jv(jvdir_0)\n",
    "        test0 = pd.concat([paramdf_0, metricdf_0], axis=1)\n",
    "        test1 = pd.concat([timedf_0, jvdf_0], axis=1)\n",
    "        test2 = pd.concat([test0, test1], axis=1)\n",
    "        test3 = pd.concat([test2, rawdf_0], axis=1)\n",
    "    if jvdir_0 == None:\n",
    "        test0 = pd.concat([paramdf_0, metricdf_0], axis=1)\n",
    "        test2 = pd.concat([test0, timedf_0], axis=1)\n",
    "        test3 = pd.concat([test2, rawdf_0], axis=1)\n",
    "\n",
    "    test2, test3 = rename_duplicate_cols(test2), rename_duplicate_cols(test3)\n",
    "\n",
    "    test2 = test2[~(test2['pl_intensity_0'] <= drop_low_pl)]  \n",
    "    \n",
    "    metricdf, rawdf = test2, test3\n",
    "    rawdf = rawdf.reset_index(drop=True)\n",
    "\n",
    "    # chronoglical plots\n",
    "    correlation_plot(metricdf, x_col='spincoat0', y_col='pl_intensity_0')\n",
    "    correlation_plot(metricdf, x_col='spincoat0', y_col='pl_peakev_0')\n",
    "    correlation_plot(metricdf, x_col='spincoat0', y_col='pl_fwhm_0')\n",
    "    if jvdir_0 !=None:\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='jsc_f')\n",
    "        correlation_plot(metricdf, x_col='spincoat0', y_col='jsc_f')\n",
    "\n",
    "        # compare to PL\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='jsc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_intensity_0', y_col='jsc_f')\n",
    "\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='jsc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_peakev_0', y_col='jsc_f')\n",
    "        \n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='pce_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='ff_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='voc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='jsc_f')\n",
    "        correlation_plot(metricdf, x_col='pl_fwhm_0', y_col='jsc_f')\n",
    "    correlation_matrix(metricdf)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c86dfbc17468201bf110f641e56a1df81e3c9871b3a7a52a78db9d9bb9a33d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
